
<div style={{ textAlign: "justify" }}>
<p>
We introduce <strong style="color:#5DB3E6;">Genie Envisioner (GE)</strong>, a <span style="color:#5DB3E6;">unified world-model framework</span> that learns and evaluates robotic manipulation policies in a single generative loop. The core, <strong style="color:#5DB3E6;">GE-Base</strong>, is an instruction-conditioned, multi-view video diffusion model trained on over 1 million real episodes from the AgiBot-World-Beta dataset, yielding latent trajectories that forecast both scene dynamics and plausible robot actions. <strong style="color:#5DB3E6;">GE-Act</strong> incorporates a flow-matching action expert in parallel with the foundation model, mapping latents to torque commands (54 continuous action steps) in 200 ms on commodity GPUs, and adapts within <strong>1 hour</strong> to novel embodiments such as Franka and AgileX Cobot, matching or exceeding task-specific baselines. <strong style="color:#5DB3E6;">GE-Sim</strong>, an action-conditioned neural simulator, produces thousands of closed-loop rollouts per hour on a distributed cluster, offering cost-effective evaluation and high-throughput policy sampling. <strong style="color:#5DB3E6;">GE-Bench</strong> completes the platform with metrics for visual fidelity, physical consistency, and instruction–action alignment. Together, these components make GE a scalable foundation for general-purpose robotic manipulation. Code, pretrained weights, and GE-Bench will be released upon publication.
</p>


</div>
