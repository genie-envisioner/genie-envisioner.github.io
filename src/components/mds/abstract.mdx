
<div style={{ textAlign: "justify" }}>
<p>
We introduce <strong style="color:#5DB3E6;">Genie Envisioner (GE)</strong>, a <span style="color:#5DB3E6;">unified world-model framework</span> that learns and evaluates robotic manipulation policies in a single generative loop. The core, <strong style="color:#5DB3E6;">GE-Base</strong>, is an instruction-conditioned, multi-view video diffusion model trained on over 1 million real-world episodes from the AgiBot-World-Beta corpus, capturing scene dynamics and robot-environment interactions in a structured latent space. G<strong style="color:#5DB3E6;">GE-Act</strong>, built in parallel with the foundation model, incorporates a flow-matching action expert to map these latents to predict 54-step torque trajectories in 200 ms on commodity GPUs. It demonstrates strong task execution capabilities on the in-domain <strong>AgiBot G1</strong> platform, and generalizes to novel embodiments Franka and AgileX Cobot with only 1 hour of teleoperated data. <strong style="color:#5DB3E6;">GE-Sim</strong> provides a closed-loop, action-conditioned neural simulator capable of generating <strong>thousands of rollouts per hour</strong> for efficient evaluation and policy training. <strong style="color:#5DB3E6;">GE-Bench</strong> further complements GE with standardized metrics for visual fidelity, physical consistency, and instruction–action alignment. Together, these components form a practical and scalable foundation for general-purpose robotic manipulation.
</p>



</div>
