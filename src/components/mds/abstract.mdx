# Abstract
<div style={{ textAlign: "justify" }}>
We introduce Genie Envisioner (GE), a unified world foundation platform for robotic manipulation, leveraging video generation to enable the generation, control, simulation, and evaluation of embodied behaviors. At its core is GE-Base, a large-scale instruction-conditioned video generative model trained on over 1M real-world manipulation sequences from the AgiBot-World-Beta dataset. GE-Base captures spatial, temporal, and semantic patterns of robot-environment interactions, enabling instruction-aligned video synthesis across diverse tasks. To bridge with action, we introduce GE-Act, a lightweight flow-matching world action model that decodes action policies from GE-Baseâ€™s latent space. Additionally, GE-Sim, a video-based neural simulator, enables real-time policy simulation in a closed-loop setup. We propose GE-Bench, a benchmark suite for evaluating video quality in real-world tasks, focusing on visual fidelity, temporal coherence, and instruction-action consistency. 
</div>
